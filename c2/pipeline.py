# -*- coding: UTF-8 -*-
# c2/pipeline.py

import json
import logging
import os
import sys
from datetime import datetime  # ğŸ”¥ [æ–°å¢]

# === è·¯å¾„é…ç½® ===
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
sys.path.append(project_root)
sys.path.append(os.getcwd())

# === æ¨¡å—å¯¼å…¥ ===
from general.model import QwenChat
from c2.definitions import MemoryNode, AtomCategory, NodeType
from c2.graph_storage import MemoryGraph

# å¯¼å…¥å„ä¸ªæ„å»ºå™¨
from c2.builders.temporal import TemporalBuilder
from c2.builders.semantic import BasicSemanticBuilder
from c2.builders.structural import StructuralBuilder
from c2.builders.evolution import EvolutionBuilder
from c2.builders.emergence import EmergenceBuilder

# æ—¥å¿—é…ç½®
logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)


class MemoryGraphPipeline:
    def __init__(self, c1_output_path: str, output_path: str, config_path: str):
        self.c1_path = c1_output_path
        self.output_path = output_path

        print("\n" + "=" * 50)
        print("ğŸš€ [Pipeline] åˆå§‹åŒ– QwenChat (Local vLLM)...")
        try:
            self.llm = QwenChat(config_path=config_path)
        except Exception as e:
            logger.warning(f"âŒ LLM init failed: {e}")
            self.llm = None

        self.semantic_builder = BasicSemanticBuilder(self.llm)
        print("âœ… [Pipeline] åˆå§‹åŒ–å®Œæˆ")
        print("=" * 50 + "\n")

    def _parse_timestamp(self, ts_val) -> float:
        """ğŸ”¥ [æ–°å¢] é²æ£’çš„æ—¶é—´æˆ³è§£æå‡½æ•°"""
        if ts_val is None:
            return 0.0
        if isinstance(ts_val, (int, float)):
            return float(ts_val)
        if isinstance(ts_val, str):
            try:
                # å°è¯•è§£ææ ‡å‡†æ ¼å¼ "2023-05-08 13:56:00"
                dt = datetime.strptime(ts_val, "%Y-%m-%d %H:%M:%S")
                return dt.timestamp()
            except ValueError:
                # å¦‚æœæ ¼å¼ä¸å¯¹ï¼Œå°è¯•å…¶ä»–æ ¼å¼æˆ–ç›´æ¥è¿”å› 0
                return 0.0
        return 0.0

    def process_single_sample(self, sample_data: dict) -> dict:
        source_id = sample_data.get("source_id", "unknown")

        # 1. åˆ›å»ºå›¾
        graph = MemoryGraph()

        # 2. åŠ è½½åŸå­
        atoms_list = sample_data.get("memory_atoms", [])
        if not atoms_list and isinstance(sample_data, list):
            atoms_list = sample_data

        for idx, atom_data in enumerate(atoms_list):
            cat_str = atom_data.get('atom_type', 'unknown')
            try:
                category = AtomCategory(cat_str)
            except ValueError:
                category = AtomCategory.UNKNOWN

            # ğŸ”¥ [ä¿®æ­£] ä½¿ç”¨è§£æåçš„ float æ—¶é—´æˆ³
            ts_float = self._parse_timestamp(atom_data.get('timestamp'))

            node = MemoryNode(
                node_id=atom_data.get('id', f"node_{idx}"),
                content=atom_data.get('content', ''),
                category=category,
                node_type=MemoryNode.map_category_to_type(cat_str),
                timestamp=ts_float,  # è¿™é‡Œä¼ å…¥ float
                embedding=atom_data.get('embedding'),
                meta=atom_data
            )
            graph.add_node(node)

        nodes = graph.get_all_nodes()
        if not nodes: return None

        print(f"\nğŸ”· Processing Sample: {source_id} | Atoms: {len(nodes)}")

        # === 3. æ‰§è¡Œ Phase ===

        # Phase 1
        self.semantic_builder.process(nodes, graph)
        try:
            TemporalBuilder().process(nodes, graph)
        except Exception as e:
            print(f"âŒ [Temporal] Error: {e}")

        # Phase 2
        try:
            EvolutionBuilder(self.llm).process(nodes, graph)
        except Exception as e:
            print(f"âŒ [Evolution] Error: {e}")

        # Phase 3 & 4
        try:
            StructuralBuilder(self.llm).process(nodes, graph)
        except Exception as e:
            print(f"âŒ [Structural] Error: {e}")

        # Phase 5
        try:
            EmergenceBuilder(self.llm).process(nodes, graph)
        except Exception as e:
            print(f"âŒ [Emergence] Error: {e}")

        # 4. ç»Ÿè®¡ç»“æœ
        n_count = graph.graph.number_of_nodes()
        e_count = graph.graph.number_of_edges()
        print(f"âœ… [Done] Stats: Nodes={n_count}, Edges={e_count}")

        # åºåˆ—åŒ–
        graph_data = graph.get_nx_graph()
        import networkx.readwrite.json_graph as json_graph
        json_data = json.loads(json.dumps(json_graph.node_link_data(graph_data)))

        return {
            "source_id": source_id,
            "graph_data": json_data
        }

    def run(self):
        if not os.path.exists(self.c1_path):
            print(f"âŒ Input file not found: {self.c1_path}")
            return

        os.makedirs(os.path.dirname(self.output_path), exist_ok=True)

        processed_count = 0
        with open(self.c1_path, 'r', encoding='utf-8') as fin, \
                open(self.output_path, 'w', encoding='utf-8') as fout:

            for line in fin:
                if not line.strip(): continue
                try:
                    sample = json.loads(line)
                    result = self.process_single_sample(sample)

                    if result:
                        fout.write(json.dumps(result, ensure_ascii=False) + "\n")
                        processed_count += 1

                except Exception as e:
                    print(f"âŒ Critical Error processing line: {e}")

        print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆï¼å…±ç”Ÿæˆ {processed_count} å¼ å›¾è°±ã€‚")
        print(f"ç»“æœå·²ä¿å­˜è‡³: {self.output_path}")


if __name__ == "__main__":
    CONFIG_PATH = "config/llm_config.yaml"
    # ğŸ”¥ ç¡®ä¿è¿™é‡ŒæŒ‡å‘ä½ æ‰“è¿‡ Embedding è¡¥ä¸çš„æ–‡ä»¶
    C1_OUTPUT = "c1/output/locomo_extracted_atoms_with_emb.jsonl"
    C2_OUTPUT = "c2/output/memory_graphs.jsonl"

    pipeline = MemoryGraphPipeline(C1_OUTPUT, C2_OUTPUT, CONFIG_PATH)
    pipeline.run()