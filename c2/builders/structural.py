# -*- coding: UTF-8 -*-
"""
@Project Ôºögraduate 
@File    Ôºöstructural.py
@Author  Ôºöniu
@Date    Ôºö2026/1/8 13:26 
@Desc    Ôºö
"""

import sys
import os
import random
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from typing import List

# === Ë∑ØÂæÑ‰∏éÈÖçÁΩÆÂØºÂÖ• ===
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
sys.path.append(project_root)

# ÂØºÂÖ•ÈÖçÁΩÆ
try:
    from ..config import (
        GNN_IN_DIM, GNN_HIDDEN_DIM, GNN_OUT_DIM, GNN_RELATIONS,
        GNN_EPOCHS, GNN_LR, LINK_PREDICTION_THRESHOLD, LLM_CONFIG_PATH
    )
except ImportError:
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from config import (
        GNN_IN_DIM, GNN_HIDDEN_DIM, GNN_OUT_DIM, GNN_RELATIONS,
        GNN_EPOCHS, GNN_LR, LINK_PREDICTION_THRESHOLD, LLM_CONFIG_PATH
    )

# ÂØºÂÖ• LLM
try:
    from general.model import ZhipuChat
except ImportError:
    try:
        from model import ZhipuChat
    except ImportError:
        pass

    # ÂØºÂÖ• PyG
try:
    from torch_geometric.nn import RGCNConv

    HAS_PYG = True
except ImportError:
    HAS_PYG = False
    print("‚ùå [Error] torch_geometric import failed. GNN training will be skipped.")

from .base import BaseGraphBuilder
from ..definitions import EdgeType, GraphNode
from ..graph_storage import AtomGraph
from ..prompts import LOGIC_VERIFICATION_PROMPT


# ==========================================
# üß† 1. ÂÆö‰πâÁúüÊ≠£ÁöÑ GNN Ê®°Âûã (Encoder)
# ==========================================
class NeuroSymbolicGNN(nn.Module):
    """
    [Real Model] Á•ûÁªèÁ¨¶Âè∑ÂõæÁ•ûÁªèÁΩëÁªú
    Êû∂ÊûÑ: RGCN (Encoder) -> Dot Product (Decoder)
    """

    def __init__(self, in_dim, hidden_dim, out_dim, num_relations):
        super().__init__()
        if HAS_PYG:
            # Á¨¨‰∏ÄÂ±Ç: ÂéãÁº©ËØ≠‰πâÔºåËûçÂêàÈÇªÂ±Ö‰ø°ÊÅØ
            self.conv1 = RGCNConv(in_dim, hidden_dim, num_relations)
            # Á¨¨‰∫åÂ±Ç: Ëøõ‰∏ÄÊ≠•ÊäΩË±°Âá∫ÁªìÊûÑÂåñÁâπÂæÅ
            self.conv2 = RGCNConv(hidden_dim, out_dim, num_relations)

            # ÊøÄÊ¥ª‰∏éÊ≠£ÂàôÂåñ
            self.relu = nn.ReLU()
            self.dropout = nn.Dropout(0.2)

    def encode(self, x, edge_index, edge_type):
        """ÁîüÊàêËäÇÁÇπÁöÑÁªìÊûÑÂåñ Embedding (z)"""
        if not HAS_PYG: return x

        # Layer 1
        x = self.conv1(x, edge_index, edge_type)
        x = self.relu(x)
        x = self.dropout(x)

        # Layer 2
        x = self.conv2(x, edge_index, edge_type)
        return x

    def decode(self, z, edge_index):
        """
        ÈìæË∑ØÈ¢ÑÊµãËß£Á†ÅÂô® (Link Prediction Decoder)
        ËÆ°ÁÆóËæπ‰∏§Á´ØËäÇÁÇπÁöÑÁõ∏‰ººÂ∫¶ÂàÜÊï∞
        """
        # z[src] * z[dst]
        src, dst = edge_index
        score = (z[src] * z[dst]).sum(dim=-1)
        return score


# ==========================================
# üèóÔ∏è 2. StructuralBuilder (Â∏¶ËÆ≠ÁªÉÂæ™ÁéØ)
# ==========================================
class StructuralBuilder(BaseGraphBuilder):
    def __init__(self):
        # ‰ΩøÁî® Config ‰∏≠ÁöÑÈÖçÁΩÆ
        self.in_dim = GNN_IN_DIM
        self.hidden_dim = GNN_HIDDEN_DIM
        self.out_dim = GNN_OUT_DIM
        self.num_rels = GNN_RELATIONS

        self.epochs = GNN_EPOCHS
        self.lr = GNN_LR
        self.threshold = LINK_PREDICTION_THRESHOLD

        # ÂàùÂßãÂåñÊ®°Âûã
        self.model = NeuroSymbolicGNN(self.in_dim, self.hidden_dim, self.out_dim, self.num_rels)
        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)

        # ÂàùÂßãÂåñ LLM (È™åËØÅÁî®)
        self.llm = ZhipuChat(LLM_CONFIG_PATH)

    def process(self, new_nodes: List[GraphNode], graph: AtomGraph):
        print("  [Structural] ÂáÜÂ§áÂêØÂä® GNN Ëá™ÁõëÁù£ËÆ≠ÁªÉ...")

        nodes = graph.get_all_nodes()
        if not nodes: return
        node_map = {n.id: i for i, n in enumerate(nodes)}

        # === A. Êï∞ÊçÆÂáÜÂ§á (Graph -> PyG Data) ===
        x_list = []
        for n in nodes:
            if n.embedding is not None and len(n.embedding) > 0:
                x_list.append(torch.tensor(n.embedding))
            else:
                x_list.append(torch.randn(self.in_dim))  # Fallback

        x = torch.stack(x_list)

        # ÊûÑÂª∫Ëæπ (Edge Index)
        edge_indices = []
        edge_types = []

        type_map = {EdgeType.SEMANTIC: 0, EdgeType.TEMPORAL: 1, EdgeType.VERSION: 2, EdgeType.IMPLICIT: 3}

        edge_count = 0
        for n in nodes:
            u = node_map[n.id]
            for e in n.edges:
                if e.target in node_map:
                    v = node_map[e.target]
                    edge_indices.append([u, v])
                    edge_types.append(type_map.get(e.type, 0))
                    edge_count += 1

        if edge_count == 0:
            print("    ‚ö†Ô∏è Âõæ‰∏≠ÊöÇÊó†ËæπÔºåË∑≥Ëøá GNN ËÆ≠ÁªÉ„ÄÇ")
            return

        edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()
        edge_type = torch.tensor(edge_types, dtype=torch.long)

        # === B. Ëá™ÁõëÁù£ËÆ≠ÁªÉ (Self-Supervised Training) ===
        z = x
        if HAS_PYG:
            self._train_gnn(x, edge_index, edge_type)

            # ÁîüÊàêÊúÄÁªàÁöÑ embedding z
            self.model.eval()
            with torch.no_grad():
                z = self.model.encode(x, edge_index, edge_type)

        # === C. Âè¨Âõû‰∏éÈ™åËØÅ (Recall & Verify) ===
        self._predict_links(z, new_nodes, nodes, node_map, graph)

    def _train_gnn(self, x, edge_index, edge_type):
        """ËÆ≠ÁªÉÂæ™ÁéØ"""
        print(f"    üèãÔ∏è [GNN Training] Start ({self.epochs} epochs)...")
        self.model.train()

        final_loss = 0.0
        for epoch in range(self.epochs):
            self.optimizer.zero_grad()

            z = self.model.encode(x, edge_index, edge_type)
            pos_score = self.model.decode(z, edge_index)
            neg_edge_index = self._negative_sampling(edge_index, x.size(0))
            neg_score = self.model.decode(z, neg_edge_index)

            pos_loss = F.binary_cross_entropy_with_logits(pos_score, torch.ones_like(pos_score))
            neg_loss = F.binary_cross_entropy_with_logits(neg_score, torch.zeros_like(neg_score))
            loss = pos_loss + neg_loss

            loss.backward()
            self.optimizer.step()
            final_loss = loss.item()

        print(f"    ‚úÖ [GNN Training] Done. Final Loss: {final_loss:.4f}")

    def _negative_sampling(self, edge_index, num_nodes):
        """ÁÆÄÂçïÈöèÊú∫Ë¥üÈááÊ†∑"""
        num_edges = edge_index.size(1)
        neg_edge_index = torch.randint(0, num_nodes, (2, num_edges), dtype=torch.long)
        return neg_edge_index

    def _predict_links(self, z, new_nodes, all_nodes, node_map, graph):
        """Êé®ÁêÜÈò∂ÊÆµÔºöÂü∫‰∫éËÆ≠ÁªÉÂ•ΩÁöÑ z ÊâæÊñ∞ËøûÊé•"""
        new_idxs = [node_map[n.id] for n in new_nodes if n.id in node_map]

        # Âä®ÊÄÅËÆ°ÁÆó Top-K (ÈÅøÂÖçËäÇÁÇπËøáÂ∞ëÊä•Èîô)
        num_nodes = len(all_nodes)
        k = min(5, num_nodes)
        if k == 0: return

        for i in new_idxs:
            sims = torch.cosine_similarity(z[i].unsqueeze(0), z)
            top_vals, top_idxs = torch.topk(sims, k=k)

            for val, idx in zip(top_vals, top_idxs):
                j = idx.item()
                if i == j: continue

                source_node = all_nodes[i]
                target_node = all_nodes[j]

                if any(e.target == target_node.id for e in source_node.edges): continue

                # === LLM È™åËØÅ ===
                if val > self.threshold:
                    print(
                        f"    üîç [GNN Proposal] '{source_node.content[:8]}...' <-> '{target_node.content[:8]}...' (Score: {val:.2f})")

                    if self._llm_verify(source_node, target_node):
                        print(f"      ‚úÖ [LLM Verified] Âª∫Á´ãÈöêÂºèÂÖ≥ËÅî (Implicit Link)")
                        graph.add_edge(source_node.id, target_node.id, EdgeType.IMPLICIT, weight=val.item())

    def _llm_verify(self, n1, n2) -> bool:
        prompt = LOGIC_VERIFICATION_PROMPT.format(text_a=n1.content, text_b=n2.content)
        try:
            result = self.llm.chat([{"role": "user", "content": prompt}])
            if isinstance(result, dict):
                return "PASS" in result.get("status", "REJECT").upper()
            return "PASS" in str(result).upper()
        except:
            return False