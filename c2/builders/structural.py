# -*- coding: UTF-8 -*-
# c2/builders/structural.py

import torch
import torch.nn as nn
import torch.optim as optim
import logging
from typing import List

# [FIX] æ­£ç¡®çš„å¯¼å…¥
from c2.builders.base import BaseGraphBuilder
from c2.definitions import EdgeType, MemoryNode

logger = logging.getLogger(__name__)

# [SIMPLIFIED] å°è¯•å¯¼å…¥ PyG (PyTorch Geometric)ã€‚
try:
    from torch_geometric.nn import RGCNConv

    HAS_PYG = True
except ImportError:
    HAS_PYG = False
    logger.warning("âš ï¸ torch_geometric æœªå®‰è£…ã€‚GNN æ¨¡å—å°†è¿è¡Œåœ¨ç®€æ˜“æ¨¡å¼ã€‚")


class NeuroSymbolicGNN(nn.Module):
    """
    [THESIS] ç¥ç»ç¬¦å·ç¼–ç å™¨
    ä½¿ç”¨ RGCN (Relational Graph Convolutional Network) å¤„ç†å¼‚æ„å›¾ã€‚
    """

    def __init__(self, in_dim, hidden_dim, out_dim, num_relations):
        super().__init__()
        self.dummy_param = nn.Parameter(torch.empty(0))
        if HAS_PYG:
            self.conv1 = RGCNConv(in_dim, hidden_dim, num_relations)
            self.conv2 = RGCNConv(hidden_dim, out_dim, num_relations)
            self.relu = nn.ReLU()
            self.dropout = nn.Dropout(0.2)

    def encode(self, x, edge_index, edge_type):
        if not HAS_PYG: return x
        x = self.conv1(x, edge_index, edge_type)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.conv2(x, edge_index, edge_type)
        return x


class StructuralBuilder(BaseGraphBuilder):  # [FIX] ç»§æ‰¿ BaseGraphBuilder
    """
    [THESIS] Phase 3 & 4: éšå¼å¬å›ä¸éªŒè¯
    """

    def __init__(self, llm_client):
        super().__init__()
        # [SIMPLIFIED] å‚æ•°ç¡¬ç¼–ç 
        self.in_dim = 384  # MiniLM çš„ç»´åº¦æ˜¯ 384, å¦‚æœæ˜¯ random åˆ™æ˜¯ 384
        self.hidden_dim = 64
        self.out_dim = 32
        self.num_rels = 5

        self.llm = llm_client
        self.model = NeuroSymbolicGNN(self.in_dim, self.hidden_dim, self.out_dim, self.num_rels)
        self.optimizer = optim.Adam(self.model.parameters(), lr=0.01)

    def process(self, new_nodes: List[MemoryNode], graph):
        # 1. å‡†å¤‡æ•°æ®
        nodes = graph.get_all_nodes()
        if len(nodes) < 3: return

        node_map = {n.node_id: i for i, n in enumerate(nodes)}

        # [SIMPLIFIED] ç‰¹å¾åˆå§‹åŒ–
        # å¦‚æœ BasicSemanticBuilder è·‘æˆåŠŸäº†ï¼Œè¿™é‡Œåº”è¯¥æœ‰ embedding
        # å¦‚æœæ²¡æœ‰ï¼Œç”¨éšæœºå‘é‡å…œåº•ï¼Œä¿è¯ä»£ç ä¸å´©
        x_list = []
        for n in nodes:
            if n.embedding and len(n.embedding) > 0:
                # ç¡®ä¿ç»´åº¦å¯¹é½ï¼Œå¦‚æœç»´åº¦ä¸å¯¹ï¼ˆæ¯”å¦‚æ¢äº†æ¨¡å‹ï¼‰ï¼Œæˆªæ–­æˆ–è¡¥é›¶
                tensor_emb = torch.tensor(n.embedding)
                if tensor_emb.shape[0] != self.in_dim:
                    # ç®€å•é‡æ–°åˆå§‹åŒ–ä¸€ä¸ªéšæœºçš„
                    x_list.append(torch.randn(self.in_dim))
                else:
                    x_list.append(tensor_emb)
            else:
                x_list.append(torch.randn(self.in_dim))
        x = torch.stack(x_list)

        # æ„å»ºè¾¹ç´¢å¼•
        edges = graph.get_all_edges()
        edge_indices = []
        edge_types = []

        edge_type_map = {
            EdgeType.SEMANTIC: 0, EdgeType.TEMPORAL: 1,
            EdgeType.VERSION: 2, EdgeType.IMPLICIT: 3, EdgeType.ABSTRACT: 4
        }

        for u, v, attr in edges:
            if u in node_map and v in node_map:
                edge_indices.append([node_map[u], node_map[v]])
                etype = attr.get('type', EdgeType.SEMANTIC)

                # [FIX] å…¼å®¹å¤„ç†ï¼šetype å¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ– Enum
                if hasattr(etype, 'value'):  # æ˜¯ Enum
                    # æ‰¾åˆ°å¯¹åº”çš„ key
                    for k, val in edge_type_map.items():
                        if k.value == etype.value:
                            edge_types.append(val)
                            break
                    else:
                        edge_types.append(0)
                else:  # æ˜¯å­—ç¬¦ä¸²
                    # å°è¯•åŒ¹é…å­—ç¬¦ä¸²
                    found = False
                    for k, val in edge_type_map.items():
                        if k.value == etype:
                            edge_types.append(val)
                            found = True
                            break
                    if not found: edge_types.append(0)

        if not edge_indices: return

        edge_index = torch.tensor(edge_indices, dtype=torch.long).t()
        edge_type = torch.tensor(edge_types, dtype=torch.long)

        # 2. è‡ªç›‘ç£è®­ç»ƒ GNN
        if HAS_PYG:
            self.model.train()
            for _ in range(5):  # [SIMPLIFIED] åªè®­ç»ƒ 5 epoch
                self.optimizer.zero_grad()
                z = self.model.encode(x, edge_index, edge_type)
                loss = torch.mean(z ** 2)
                loss.backward()
                self.optimizer.step()

        # 3. éšå¼å¬å›
        self.model.eval()
        with torch.no_grad():
            if HAS_PYG:
                z = self.model.encode(x, edge_index, edge_type)
            else:
                z = x

            sim_matrix = torch.matmul(z, z.t())

        # 4. è¯­ä¹‰éªŒè¯
        # [SIMPLIFIED] é˜ˆå€¼è®¾ä½ç‚¹ä»¥ä¾¿çœ‹åˆ°æ•ˆæœ
        threshold = 3.0
        rows, cols = torch.where(sim_matrix > threshold)

        candidates = []
        existing_edges = set((u, v) for u, v, _ in edges)

        for r, c in zip(rows, cols):
            if len(candidates) >= 2: break  # [SIMPLIFIED] é™åˆ¶æ•°é‡
            if r >= c: continue

            u_node = nodes[r.item()]
            v_node = nodes[c.item()]

            if (u_node.node_id, v_node.node_id) in existing_edges: continue
            if (v_node.node_id, u_node.node_id) in existing_edges: continue

            candidates.append((u_node, v_node))

        for n1, n2 in candidates:
            if self._llm_verify(n1, n2):
                graph.add_edge(n1.node_id, n2.node_id, EdgeType.IMPLICIT)
                logger.info(f"    ğŸ”— [GNN+LLM] å‘ç°éšå¼å…³è”: {n1.content[:10]}... <-> {n2.content[:10]}...")

    def _llm_verify(self, n1, n2) -> bool:
        if not self.llm: return False
        prompt = f"""
        åˆ¤æ–­ä»¥ä¸‹ä¸¤ä¸ªç‰‡æ®µæ˜¯å¦æœ‰é€»è¾‘å…³è”ï¼Ÿ
        A: {n1.content}
        B: {n2.content}
        æœ‰åˆ™å›ç­”YESï¼Œæ— åˆ™NOã€‚
        """
        try:
            res = self.llm.chat([{"role": "user", "content": prompt}])
            content = res.get("content", "").upper() if isinstance(res, dict) else str(res).upper()
            return "YES" in content
        except:
            return False