# -*- coding: UTF-8 -*-
"""
@Project ï¼šgraduate
@File    ï¼ševal_stream_locomo.py
@Desc    ï¼šã€ç¬¬ä¸€ç« ï¼šæµå¼è¯„æµ‹æ ‡å‡†è„šæœ¬ã€‘
          åŠŸèƒ½ï¼šæ¨¡æ‹Ÿ Agent å®æ—¶å¯¹è¯ï¼ŒæŒ‰è½®æ¬¡æå–è®°å¿†å¹¶å­˜å…¥ç³»ç»Ÿï¼Œåœ¨æŒ‡å®šè§¦å‘ç‚¹è¿›è¡Œ QA æµ‹è¯•ã€‚
          æŒ‡æ ‡ï¼šè®¡ç®— F1 Score (å•è¯çº§é‡åˆåº¦)ã€‚
"""

import os
import sys
import json
import collections
import string
from tqdm import tqdm
from typing import List, Dict

# --- è·¯å¾„é€‚é… ---
current_dir = os.path.dirname(os.path.abspath(__file__))
root_dir = os.path.dirname(current_dir)
sys.path.append(root_dir)

# å¯¼å…¥ç¬¬ä¸€ç« æ ¸å¿ƒç»„ä»¶
from c1.decoupler import SemanticDecoupler, RawInputObj
from c1.verifier import ConsistencyVerifier
from c1.deduplicator import SemanticRedundancyFilter
from general.base_memory import AgenticMemorySystem
from general.model import QwenChat

# ================= é…ç½®åŒº =================
CONFIG_PATH = os.path.join(root_dir, "config", "llm_config.yaml")
TEST_DATA_PATH = os.path.join(root_dir, "dataset", "locomo10.json")
WINDOW_SIZE = 6  # è§£è€¦æ—¶å‚è€ƒçš„å†å²çª—å£å¤§å°


# =========================================

class LocomoStreamEvaluator:
    def __init__(self):
        print(">>> [Eval] åˆå§‹åŒ–æµå¼è¯„æµ‹å¼•æ“ (Baseline)...")
        # 1. åˆå§‹åŒ–å¤§æ¨¡å‹åç«¯
        self.llm = QwenChat(CONFIG_PATH)

        # 2. åˆå§‹åŒ–è®°å¿†æµæ°´çº¿ç»„ä»¶
        self.memory_sys = AgenticMemorySystem()
        self.decoupler = SemanticDecoupler(self.llm)
        self.verifier = ConsistencyVerifier(self.llm)
        self.deduplicator = SemanticRedundancyFilter(self.memory_sys, self.llm)

    def reset_system(self):
        """é‡ç½®è®°å¿†åº“ï¼Œç¡®ä¿æ ·æœ¬ä¹‹é—´ä¸å¹²æ‰°"""
        self.memory_sys.memory_manager.clear()

    def _calculate_f1(self, prediction, ground_truth):
        """è®¡ç®—å•è¯çº§ F1 Score"""

        def normalize_answer(s):
            s = str(s).lower()
            s = "".join(ch for ch in s if ch not in set(string.punctuation))
            return s.split()

        pred_tokens = normalize_answer(prediction)
        gold_tokens = normalize_answer(ground_truth)

        if not pred_tokens or not gold_tokens:
            return 1.0 if pred_tokens == gold_tokens else 0.0

        common = collections.Counter(pred_tokens) & collections.Counter(gold_tokens)
        num_same = sum(common.values())

        if num_same == 0:
            return 0.0

        precision = 1.0 * num_same / len(pred_tokens)
        recall = 1.0 * num_same / len(gold_tokens)
        f1 = (2 * precision * recall) / (precision + recall)
        return f1

    def run(self, limit=10):
        """æ‰§è¡Œè¯„æµ‹ï¼Œlimit å‚æ•°ç”¨äºé™åˆ¶æµ‹è¯•æ ·æœ¬æ•°ä»¥èŠ‚çœæ—¶é—´"""
        if not os.path.exists(TEST_DATA_PATH):
            print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ•°æ®é›†æ–‡ä»¶ {TEST_DATA_PATH}")
            return

        with open(TEST_DATA_PATH, 'r', encoding='utf-8') as f:
            data = json.load(f)

        test_samples = data[:limit]
        all_f1_scores = []

        print(f"\nğŸš€ å¼€å§‹è¯„æµ‹ | æ¨¡å¼: Baseline | æ ·æœ¬æ•°: {len(test_samples)}")
        print("-" * 50)

        for sample in tqdm(test_samples, desc="Processing Samples"):
            self.reset_system()

            # å»ºç«‹é—®é¢˜ç´¢å¼•ï¼šå“ªäº›è½®æ¬¡éœ€è¦è§¦å‘æé—®
            q_map = {}
            for q in sample.get('questions', []):
                idx = q.get('trigger_turn', -1)
                q_map.setdefault(idx, []).append(q)

            # æ•´ç†å¯¹è¯æµ (å°†æ‰€æœ‰ Session å±•å¹³ä¸º Turn åºåˆ—)
            history_buffer = []
            all_turns = []
            sessions = sample['conversation']['sessions']
            for s_id in sorted(sessions.keys()):
                all_turns.extend(sessions[s_id]['turns'])

            # --- æµå¼å¾ªç¯ ---
            for i, turn in enumerate(all_turns):
                current_text = f"[{turn['speaker']}]: {turn['text']}"
                context_text = "\n".join(history_buffer[-WINDOW_SIZE:]) if history_buffer else ""

                # 1. è®°å¿†å¤„ç†ï¼šè§£è€¦ -> æ ¡éªŒ -> å»é‡å…¥åº“
                try:
                    raw_obj = RawInputObj(text=current_text, context=context_text)
                    dirty_atoms = self.decoupler.decouple(raw_obj)
                    if dirty_atoms:
                        full_evidence = f"{context_text}\n{current_text}"
                        clean_atoms = self.verifier.verify_batch(dirty_atoms, full_evidence)
                        if clean_atoms:
                            self.deduplicator.filter_and_add_batch(clean_atoms)
                except Exception as e:
                    pass  # è¯„æµ‹æ—¶å¿½ç•¥å•è½®æ¬¡å¼‚å¸¸

                # æ›´æ–°å†å²çª—å£
                history_buffer.append(current_text)

                # 2. æ£€æŸ¥æ˜¯å¦æœ‰é—®é¢˜è§¦å‘
                if i in q_map:
                    for q_item in q_map[i]:
                        # A. æ£€ç´¢è®°å¿†
                        relevant_mems = self.memory_sys.retrieve(q_item['question'], k=5)
                        mem_context = "\n".join([f"- {m.content}" for m in relevant_mems])

                        # B. ç”Ÿæˆç­”æ¡ˆ
                        answer_prompt = f"""Based on the memories below, answer the question briefly.
Memories:
{mem_context}

Question: {q_item['question']}
Answer:"""
                        prediction = self.llm.chat(user_input=answer_prompt)

                        # C. è¯„åˆ†
                        f1 = self._calculate_f1(prediction, q_item['answer'])
                        all_f1_scores.append(f1)

        # æœ€ç»ˆæ±‡æ€»
        if all_f1_scores:
            final_score = sum(all_f1_scores) / len(all_f1_scores)
            print(f"\n{'=' * 40}")
            print(f"âœ… è¯„æµ‹å®Œæˆ | Final Result")
            print(f"   å¹³å‡ F1 åˆ†æ•°: {final_score:.4f}")
            print(f"{'=' * 40}")
        else:
            print("\nâš ï¸ è¯„æµ‹æœªäº§å‡ºæœ‰æ•ˆåˆ†æ•°ï¼Œè¯·æ£€æŸ¥æ•°æ®é›† trigger_turn æ˜¯å¦æ­£ç¡®ã€‚")


if __name__ == "__main__":
    evaluator = LocomoStreamEvaluator()
    # ç¬¬ä¸€æ¬¡å»ºè®®å…ˆè·‘ 5-10 ä¸ªæ ·æœ¬çœ‹æ•ˆæœ
    evaluator.run(limit=10)